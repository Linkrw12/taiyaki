#!/usr/bin/env python3

import argparse
import matplotlib as mpl
mpl.use('Agg')  # So we don't need an x server
import numpy as np
import os
from Bio import SeqIO
import matplotlib.pyplot as plt
import statsmodels.api as sm
from taiyaki import fileio


parser = argparse.ArgumentParser(
    description='Calculate parameters to correct qscores as predictor of ' +
    'per-read error rate',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

parser.add_argument("--alignment_summary", default=None,
                    help="Input: tsv file containing alignment summary")

parser.add_argument("--coverage_threshold", default=0.8, type=float,
                    help="Disregard reads with coverage less than this")

parser.add_argument("--max_alignment_score", default=40.0, type=float,
                    help="Upper limit on score calculated from alignment")

parser.add_argument("--min_fastqscore", default=7.0, type=float,
                    help="Lower limit on score calculated from fastq")


parser.add_argument("--fastq", default=None,
                    help="Input: fastq file")

parser.add_argument("--input_directory", default=None,
                    help="Input directory containing fastq files and " +
                    "alignment_summary.txt (use either this arg or --fastq")

parser.add_argument('--maxreads', default=None, type=int,
                    help="Max reads to process (default to no max)")

parser.add_argument("--plot_title", default=None,
                    help="Add this title to plot")

parser.add_argument("--plot_filename", default='qscore_calibration.png',
                    help="Output: file name for plot.")


def fastq_file_qscore(qvector):
    """Work out an 'average' q score from an array of q scores in a fastq.
    (It's really the q score that goes with the mean error rate.)

    :param qvector: numpy vector of q scores from fastq (may be int or float)

    :return: single qscore (float) for file."""
    # Error probability at each location
    p = np.power(10.0, -qvector.astype(np.float64) / 10.0)
    # Whole-file mean error rate
    e = np.mean(p)
    return -10.0 * np.log10(e)


def read_fastqs(fastqlist, maxreads=None, reads_per_dot=100):
    """Read fastq files and calculate length and mean q score for each

    :param fastqlist: list of fastq files
    :param reads_per_dot: integer. Print a dot for every reads_per_dot files
    :param maxreads: max number of files to read

    :return: tuple (read_ids, mean_qscores, lengths)
             where read_id_list is a np array of strs containing read ids
                   mean_qscore_list is a np array of float mean qscores
                         (or nan if no data found in the file)
                    lengths is a np array of integers giving the number of
                       bases in each basecall
    """
    read_id_list = []
    mean_qscore_list = []
    length_list = []
    print("Printing one dot for every {} reads.".format(reads_per_dot))
    for fastqfile in fastqlist:
        for record in SeqIO.parse(fastqfile, "fastq"):
            read_id_list.append(record.id)
            scores = np.array(
                record.letter_annotations["phred_quality"])
            length_list.append(len(scores))
            if len(scores) > 0:
                mean_qscore_list.append(fastq_file_qscore(scores))
            else:
                mean_qscore_list.append(None)
            if (len(read_id_list) + 1) % reads_per_dot == 0:
                print(".", end="")
            if maxreads is not None:
                if len(read_id_list) >= maxreads:
                    break
        if maxreads is not None:
            if len(read_id_list) >= maxreads:
                break
    print("")
    return (np.array(read_id_list),
            np.array(mean_qscore_list),
            np.array(length_list))


def get_alignment_data(alignment_file):
    """Read alignment summary generated by Guppy or Taiyaki, getting accuracy
    and length of aligned part of read for each read id

    :param alignment_file: file path pointing to either
                            Taiyaki  (.samacc)  or Guppy (.txt)
                            alignment summary

    :return: tuple (read_ids, accuracies, alignment_lens)
             where read_ids is a numpy array of strs
                   accuracies is a numpy array of floats (0-1)
                   alignment_lens is a numpy array of ints
                      giving the read (i.e. 'strand') alignment length.
                      -1 is used as a marker for null in this array.

    :note: The resulting table may have more than one entry for each read id
           (because there may be more than one possible alignment)

    """
    # Delimiter None accepts space or tab - samaccs are space-separated.
    t = fileio.readtsv(alignment_file, delimiter=None)

    try:
        # Try to read the file as a Guppy alignment summary file
        read_ids = t['read_id']
        accuracies = t['alignment_accuracy']
        alignment_lens = (t['alignment_strand_end']
                          - t['alignment_strand_start'])
        print("Interpreted alignment file as Guppy output")
        accuracies[accuracies < 0] = np.nan
        return read_ids, accuracies, alignment_lens
    except ValueError:
        # Thrown if the required fields are not present in the file
        pass

    try:
        # Try to read the file as a Taiyaki alignment summary
        read_ids = t['query']
        accuracies = t['accuracy']
        # Query length in alignment not available directly in taiyaki summary
        alignment_lens = (t['reference_end']
                          - t['reference_start']
                          + t['insertion']
                          - t['deletion'])
        print("Interpreted alignment file as Taiyaki output")
        return read_ids, accuracies, alignment_lens
    except ValueError:
        pass

    columnlist = list(t.dtype.fields.keys())
    raise Exception("Alignment summary file must contain either columns " +
                    "(read_ids, alignment accuracy, alignment_strand_end, " +
                    "alignment_strand_start) or " +
                    "(id, accuracy, reference_end, reference_start, " +
                    "insertion, deletion  )" +
                    ". Columns are {}".format(columnlist))


def merge_align_fastq_data(fastq_ids,
                           alignment_ids,
                           alignment_accuracies,
                           alignment_lens):
    """Get an alignment accuracy and length of alignment in basecall
    for each id in the fastq data.

    If the alignment has more than one entry for a particular id, then
    choose the best.

    :param fastq_ids: numpy array of read ids
    :param alignment_ids: numpy array of read ids
    :param alignment_accuracies: numpy array of floats 0-1
    :param alignment_lens: numpy array of ints

    :return: tuple (fastq accuracies, fastq alignment_lens)
                    (for entries not found in the alignment we use nan
                    for nulls in the accuracy array and -1 for nulls in
                    the length array)

    """
    n_fastqs = len(fastq_ids)
    fastq_accuracies = np.full(n_fastqs, np.nan)
    fastq_alignment_lens = np.full(n_fastqs, -1)
    read_not_found = 0
    more_than_one_alignment = 0
    for nread, fastq_id in enumerate(fastq_ids):
        accuracies = alignment_accuracies[alignment_ids == fastq_id]
        lens = alignment_lens[alignment_ids == fastq_id]
        if len(accuracies) == 0:
            read_not_found += 1
        elif len(accuracies) == 1:
            fastq_accuracies[nread] = accuracies[0]
            fastq_alignment_lens[nread] = lens[0]
        else:
            more_than_one_alignment += 1
            loc = np.argmax(accuracies)
            fastq_accuracies[nread] = accuracies[loc]
            fastq_alignment_lens[nread] = lens[loc]
    print("\n{} reads read from fastq.".format(n_fastqs))
    print("    {} not found in alignment summary.".format(read_not_found))
    print("    {} with more than one alignment.\n".format(
        more_than_one_alignment))
    return fastq_accuracies, fastq_alignment_lens


def calculate_regression(mean_qscores, calc_qscores):
    """Regress mean fastq qscores against alignment-derived ones.
    Uses Huber regression as in OFAN script

    :param mean_qscores: numpy float array (x in the regression)
    :param calc_qscores: numpy float array (y in the regression)
    """
    X = sm.add_constant(mean_qscores)

    model = sm.RLM(calc_qscores, X, M=sm.robust.norms.HuberT())

    line = model.fit()
    c, m = line.params

    return c, m


def single_read_accuracy_scatter(accuracies, meanqs, max_alignment_score):
    """Do regression and plot data for single read accuracy vs mean qgenfromtxt

    :param accuracies: np vector of accuracies (floats 0-1)
    :param meanqs: np vector of mean q values (floats > 0)
    :params max_alignment_score: set alignment scores about this value to
                                 max_alignment_score

    :return: tuple (m,c)
             where qscore(accuracy) = m * meanq + c
             is the best fit, and
             qscore(x) = -10.0 log10(1-x)
    """
    y = -10.0 * np.log10(1.0 - accuracies)
    y[y > max_alignment_score] = max_alignment_score
    x = meanqs

    plt.scatter(x, y, s=2)
    #m_OLS,c_OLS, r_value, p_value, mstd_OLS = linregress(x,y)
    c, m = calculate_regression(x, y)

    xx = np.array([np.min(x), np.max(x)])
    yy = c + m * xx
    label = 'slope={:3.2f} intercept={:3.2f}'.format(m, c)
    plt.plot(xx, yy, color='gray', label=label)
    plt.plot(xx, xx, color='gray', linestyle='dotted', label='y=x')
    plt.legend(loc='upper left', framealpha=0.1)
    plt.xlabel('Fastq q score')
    plt.ylabel('Alignment accuracy score')
    plt.grid()
    return m, c


def filter_data(accuracies, fastqscores, fastq_lens, alignment_lens,
                min_coverage, min_fastqscore):
    """Remove null accuracies and coverage < min_coverage.

    :param accuracies: np float array
    :param qscores: np float array
    :param fastq_lens: np int array, lengths of fastqs
    :param alignment_lens: np int array, lengths of aligned regions
    :param min_coverage: minimum coverage fraction to include
    :param min_fastqscore: minimum fastq score to include

    :returns: filtered tuple (accuracies, qscores)

    :note: measure of coverage used (as in ONT calibration script) is
           (aligned length in basecall) / (total basecall length)
    """
    # Make filter to remove unaligned reads
    f = ~np.isnan(accuracies)

    coverage_fraction = (alignment_lens.astype(np.float64) /
                         fastq_lens.astype(np.float64))
    # Also remove coverage less than threshold (values of -1 in alignment_len
    # used to indicate null also filtered out by this step
    g = (coverage_fraction > min_coverage)

    h = (fastqscores >= min_fastqscore)

    print("Total number of reads = ", len(accuracies))
    print("    After removing those not aligned:", len(accuracies[f]))
    print("    After also removing coverage < {:3.2f}: {}".format(
        min_coverage, len(accuracies[f & g])))
    print("    After also removing fastq score < {:3.1f}: {}".format(
        min_fastqscore, len(accuracies[f & g & h])))

    return accuracies[f & g & h], fastqscores[f & g & h]


if __name__ == "__main__":
    print("Calculating shift and scale parameters to calibrate per-read")
    print("accuracy estimates from q scores.")
    args = parser.parse_args()
    fastqlist = None
    if args.input_directory is not None:
        fastqlist = [fi for fi in os.listdir(args.input_directory)
                     if fi.endswith('.fastq')]
        fastqlist = [os.path.join(args.input_directory, fi)
                     for fi in fastqlist]
        if len(fastqlist) == 0:
            errstr = "No fastq files found in {}".format(args.input_directory)
            raise Exception(errstr)
        else:
            print("Getting q scores for {} fastq files from {}".format(
                len(fastqlist), args.input_directory))
        alignment_summary_file = os.path.join(args.input_directory,
                                              'alignment_summary.txt')
    if args.fastq is not None:
        fastqlist = [args.fastq]
        if fastqlist is not None:
            print("Command-line argument fastq overrides directory list")
        print("Calculating average q scores for {}".format(args.fastq))

    if args.alignment_summary is not None:
        # args.alignment summary overrides the one in the directory.
        print("Using alignment summary file at ", args.alignment_summary)
        alignment_summary_file = args.alignment_summary

    if fastqlist is None:
        raise Exception("You must supply a directory containing " +
                        "fastqs or the path to a fastq file")

    fastq_ids, fastq_meanqs, fastq_lens = read_fastqs(fastqlist, args.maxreads)

    align_ids, align_accuracies, align_lens = get_alignment_data(
        alignment_summary_file)

    fastq_accuracies, fastq_align_lens = merge_align_fastq_data(fastq_ids,
                                                                align_ids, align_accuracies, align_lens)

    fastq_accuracies, fastq_meanqs = filter_data(fastq_accuracies,
                                                 fastq_meanqs,
                                                 fastq_lens,
                                                 fastq_align_lens,
                                                 args.coverage_threshold,
                                                 args.min_fastqscore)

    slope, intercept = single_read_accuracy_scatter(fastq_accuracies,
                                                    fastq_meanqs,
                                                    args.max_alignment_score)

    print("\n\nBest-fit:", args.plot_title)
    print("Best-fit slope (qscore_scale) = {:3.4f}".format(slope))
    print("Best-fit shift (qscore_shift) = {:3.4f}".format(intercept))

    if args.plot_title is not None:
        plt.title(args.plot_title)

    print("\nSaving plot to {}".format(args.plot_filename))
    plt.savefig(args.plot_filename)
    plt.close()
